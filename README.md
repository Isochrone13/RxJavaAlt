# Вывод и рекомендации по настройке CustomThreadPoolExecutor

## Вывод по производительности

Наши бенчмарки показали, что при небольшом числе задач (200–1 000) стандартный `FixedThreadPool(10)` и кастомный пул демонстрируют схожую пропускную способность, а при больших объёмах (10 000 задач) **CustomThreadPoolExecutor** начинает **превосходить** за счёт уменьшения конкуренции на очередях и гибкого масштабирования.

- Для **200–1 000 задач**: throughput ≈ 175 vs 173 tasks/sec.
- Для **10 000 задач**: CustomPool — 195 tasks/sec vs FixedPool — 181 tasks/sec (**+8 %**).
- Средняя латентность остаётся в диапазоне **≈ 55 ms**, что говорит о том, что дополнительная логика не вносит заметных задержек.

## 5. Принцип распределения задач (Round-Robin)

1. **N внутренних очередей**  
   Пул содержит **N = `maxPoolSize`** независимых `BlockingQueue<Runnable>`, по одной на каждый потенциальный поток.

2. **Циклический обход**  
   Для каждой новой задачи вычисляем индекс очереди:
   ```java
   int idx = nextQueue.getAndIncrement() % N;
   ```
   Это атомарно и потокобезопасно благодаря `AtomicInteger`.

3. **Отсутствие глобальных блокировок**  
   Каждый воркер работает только со своей очередью, нет единого мьютекса, блокирующего всех рабочих.

4. **Высокая параллельная пропускная способность**  
   Round-Robin в сочетании с динамическим масштабированием (создание/завершение воркеров) позволяет пулу быстро адаптироваться к нагрузке.

## 6. Рекомендации по настройке параметров

1. **`corePoolSize` ≈ числу ядер**  
   Оптимально запускать потоков столько же, сколько аппаратных или виртуальных ядер.

2. **`maxPoolSize` ≈ 2–3 × core**  
   Позволяет обрабатывать пики нагрузки (IO-bound задачи и т.п.) без избыточного контеншена.

3. **`queueSize` ≈ 4–8 × core**  
   Средняя очередь сглаживает кратковременные всплески задач без немедленной эскалации потоков.

4. **`minSpareThreads` = 1**  
   Один резервный поток обеспечивает мгновенный отклик без постоянных затрат на поддержание «горячих» потоков.

5. **Round-Robin снижает contention**  
   При высоких объёмах задач разделение на N очередей вместо одной общей резко уменьшает нагрузку на синхронизацию и улучшает throughput.

> **Итог:** Кастомный пул с **Round-Robin**, **динамическим масштабированием** и **CallerRunsPolicy** не только сравним со стандартным `FixedThreadPool`, но и превосходит его при высоких нагрузках.
